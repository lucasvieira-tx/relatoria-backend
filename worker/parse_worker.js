import fs from "fs";
import os from "os";
import path from "path";
import { supabaseAdmin } from "./helpers/supabaseAdmin.js";
import { extractFromCSV, extractFromXLSX } from "./schemaExtractor.js";

const POLL_INTERVAL = 30000; // 24horas - 24 * 60 * 60 * 1000
const MAX_SAMPLE_SIZE = 100;

/**
 * Seleciona um dataset com status 'uploaded', marca-o como 'processing' e retorna o dataset atualizado.
 * Utiliza uma transa√ß√£o SQL para garantir atomicidade.
 *
 * @returns {Promise<object | null>} O dataset processado se a opera√ß√£o for bem-sucedida, ou `null` em caso de erro ou se nenhum dataset for encontrado.
 */
/**
 * Seleciona um dataset com status 'uploaded', marca-o como 'processing' e retorna o dataset atualizado.
 * Utiliza uma transa√ß√£o impl√≠cita (sele√ß√£o seguida de atualiza√ß√£o) para tentar garantir que apenas um worker processe um dataset por vez.
 *
 * @returns {Promise<object | null>} O dataset processado se a opera√ß√£o for bem-sucedida, ou `null` em caso de erro ou se nenhum dataset for encontrado.
 */
async function pickSimple() {
  const { data } = await supabaseAdmin
    .from("datasets")
    .select("*")
    .eq("status", "uploaded")
    .order("created_at", { ascending: true })
    .limit(1);
  if (!data || data.length === 0) return null;

  const ds = data[0];
  const { error } = await supabaseAdmin
    .from("datasets")
    .update({ status: "processing" })
    .eq("id", ds.id)
    .eq("status", "uploaded");
  if (error) {
    console.warn(
      "‚ö†Ô∏è [Worker] Could not mark dataset as processing:",
      error.message
    );
    return null;
  }

  console.log("‚úÖ [Worker] Dataset marked as processing:", ds.id);

  return ds;
}

/**
 * Processa um dataset completo: baixa o arquivo, extrai o esquema e uma amostra,
 * e atualiza o status do dataset no banco de dados.
 * Em caso de erro durante o download ou parsing, o status do dataset √© marcado como 'invalid'.
 *
 * @param {object} ds - O objeto dataset a ser processado, contendo informa√ß√µes como id, storage_path, filename, etc.
 * @returns {Promise<void>} N√£o retorna diretamente um valor, mas atualiza o estado do dataset no banco de dados.
 */
async function processDataset(ds) {
  console.log("üåê - [Worker] Processing", ds.id);

  // Download
  const { data: download, error: dlErr } = await supabaseAdmin.storage
    .from("datasets")
    .download(ds.storage_path);
  if (dlErr) {
    console.error("‚ùå - [Worker] Download error", dlErr.message);
    await supabaseAdmin
      .from("datasets")
      .update({ status: "invalid", error_message: dlErr.message })
      .eq("id", ds.id);
    return;
  }

  const buffer = Buffer.from(await download.arrayBuffer());
  // temp file if needed
  const ext = path.extname(ds.filename || ds.storage_path || "").toLowerCase();
  let result;
  try {
    if (ext === ".csv" || ext === "") {
      result = await extractFromCSV(buffer, {
        sampleRows: 30,
        maxInspect: 2000,
      });
      console.log("‚úÖ - [Worker] CSV parsed successfully");
    } else {
      result = await extractFromXLSX(buffer, { sampleRows: 30 });
      console.log("‚úÖ - [Worker] XLSX parsed successfully");
    }
  } catch (err) {
    console.error("‚ùå - [Worker] Parse error", err.message);
    await supabaseAdmin
      .from("datasets")
      .update({ status: "invalid", error_message: err.message })
      .eq("id", ds.id);
    return;
  }

  // save sample small -> DB or Storage
  const sampleJson = JSON.stringify({ sample: result.sample });
  console.log("‚úÖ - [Worker] Sample extracted successfully");
  let sample_path = null;
  console.log("‚úÖ - [Worker] Sample size: " + sampleJson.length);
  if (sampleJson.length > MAX_SAMPLE_SIZE) {
    sample_path = `datasets_samples/${ds.id}_sample.json`;
    console.log("‚úÖ - [Worker] Sample saved to storage");
    const { error: sampleErr } = await supabaseAdmin.storage
      .from("datasets_sample")
      .upload(sample_path, Buffer.from(sampleJson), {
        contentType: "application/json",
      });
    if (sampleErr) {
      console.error("‚ùå - [Worker] Sample upload error", sampleErr.message);
      await supabaseAdmin
        .from("datasets")
        .update({ status: "invalid", error_message: sampleErr.message })
        .eq("id", ds.id);
      return;
    }
  }

  // update dataset
  const upd = {
    row_count: result.row_count,
    columns: result.columns,
    size_bytes: buffer.length,
    status: "parsed",
    parsed_at: new Date().toISOString(),
    sample_path: sample_path,
    sample_json: sampleJson,
  };
  const { error: updErr } = await supabaseAdmin
    .from("datasets")
    .update(upd)
    .eq("id", ds.id);
  if (updErr) {
    console.error("‚ùå - [Worker] Update error", updErr.message);
    await supabaseAdmin
      .from("datasets")
      .update({ status: "invalid", error_message: updErr.message })
      .eq("id", ds.id);
    return;
  }
  console.log("‚úÖ - [Worker] Parsed successfully:", ds.id);
}

async function loop() {
  while (true) {
    console.log("üåê - [Worker] Looping...");
    try {
      const ds = await pickSimple();
      if (ds) {
        await processDataset(ds);
      } else {
        // nothing to do
        console.log("üåê - [Worker] No dataset to parse");
      }
    } catch (err) {
      console.error("üåê - [Worker] Worker error", err);
    }
    await new Promise((r) => setTimeout(r, POLL_INTERVAL));
  }
}

loop();
